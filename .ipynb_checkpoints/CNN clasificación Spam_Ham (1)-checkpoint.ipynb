{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN clasificación Spam/Ham.ipynb","provenance":[],"collapsed_sections":["Griwatj9Chha","YpTJHC-RC84f","iq_fmfj-FLbE","2IFXOZN2Yq1j","b28LB-qYY9wI","ymV81IiwZJuL","0kzdDMhSZbZ1"],"mount_file_id":"14TBIa0b8Casr5kaEQQhktO6fmqH6bgc5","authorship_tag":"ABX9TyND1wlDtKWMQjSwn1AMOfgL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Importar librerias"],"metadata":{"id":"Griwatj9Chha"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XRtnzgiuCM6K"},"outputs":[],"source":["import numpy as np\n","import math\n","import re # expresiones regulares\n","import pandas as pd\n","from bs4 import BeautifulSoup # para trabajar texto en varios formatos\n","\n","from google.colab import drive"]},{"cell_type":"code","source":["# El código anterior me trae la última versión de keras\n","try:\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","  \n","import tensorflow as tf\n","\n","from tensorflow.keras import layers # importar layers desde keras\n","\n","import tensorflow_datasets as tfds # este me trae los tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A56AquXUC5KY","executionInfo":{"status":"ok","timestamp":1661473089287,"user_tz":240,"elapsed":3188,"user":{"displayName":"FELIPE LERMANDA RODRIGUEZ","userId":"01039212382747188054"}},"outputId":"96053eb4-9c7c-4574-c1f3-3f94c979592b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"]}]},{"cell_type":"markdown","source":["## Cargar conjunto de datos"],"metadata":{"id":"YpTJHC-RC84f"}},{"cell_type":"code","source":["#cols=[\"resultado\",\"mensaje\"]\n","data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CNN Spam Ham/SMSSpamCollection(Filtrada).csv',\n","                 sep = \";\")\n","\n"],"metadata":{"id":"GZPns8TeC7x5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"id":"6mJOQfcrEGxM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['resultado'] = data['resultado'].apply(lambda x:1 if x == 'ham' else 0) "],"metadata":{"id":"BS0nt3QVX2Pl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"id":"peyrOQOZYdnD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Limpieza de datos"],"metadata":{"id":"iq_fmfj-FLbE"}},{"cell_type":"code","source":["def clean_tweet(tweet):\n","\n","  tweet= BeautifulSoup(tweet,\"lxml\").get_text() # sirve para trabajar en un formato especial de tratar el texto. hay que usar el get_text para que me lo devuela en un formato legible\n","  \n","  # Dejamos todo en minúscula\n","  tweet = tweet.lower()\n","  # Reemplazamos puntos por espacios\n","  tweet = tweet.replace('.',' ')\n","  # Eliminamos la @ y su mención\n","  tweet = re.sub(r\"@[A-Za-z0-9.]+\",' ',tweet) # después del @ puede leer lo que se encuentra en el []. El + significa que puede ser mas de un caracter a los que se hace referencia. \n","  # El r significa raw o string y le dice a la sentencia que lea la línea tal cual, por ejemplo si vieniera con hipervinculo que no lo considere.\n","  # Eliminamos los links de la URLs\n","  tweet = re.sub(r\"https?://[A-Za-z0-9./]+\",' ', tweet) # aqui el ? me dice que el caracter anterior puede estar o no\n","  # Nos quedamos solo con los caracteres\n","  tweet = re.sub(r\"[^a-zA-Z.!?']\",' ',tweet)# cualquier cosa que no sea lo que viene después de ^ se va a sustituir por espacios en blanco\n","  # Eliminamos los sitios web\n","  tweet = re.sub(r\"www[A-Za-z0-9./]+\",' ', tweet)\n","  # Eliminamos espacios en blanco adicionales\n","  tweet = re.sub(r\" +\",' ',tweet)# si existe más de un espacio en blanco lo reemplazamos por uno solo. El más me dice eso, si hay más de uno reemplazo\n","  return tweet"],"metadata":{"id":"A44G9k2EFFCz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_clean = [clean_tweet(tweet) for tweet in data.mensaje] # esto me queda en una lista guardado"],"metadata":{"id":"Qk5XMMJXFaF7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set(data.resultado) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8bdVT-NuFdHD","executionInfo":{"status":"ok","timestamp":1661473106463,"user_tz":240,"elapsed":13,"user":{"displayName":"FELIPE LERMANDA RODRIGUEZ","userId":"01039212382747188054"}},"outputId":"994c046e-0592-4c0f-9a92-4c2b6026c75a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0, 1}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["data_clean"],"metadata":{"id":"IMz5udJdGbHd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tokenización"],"metadata":{"id":"2IFXOZN2Yq1j"}},{"cell_type":"code","source":["# El corpus es la lista del texto que se va a analizar|\n","\n","tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    data_clean,target_vocab_size = 2**16\n",")\n","\n","data_inputs = [tokenizer.encode(sentence) for sentence in data_clean]"],"metadata":{"id":"qECRKReyXzHm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Padding"],"metadata":{"id":"b28LB-qYY9wI"}},{"cell_type":"code","source":["MAX_LEN = max(len(sentence) for sentence in data_inputs)\n","data_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n","    data_inputs,\n","    value = 0,\n","    padding = \"post\",\n","    maxlen = MAX_LEN\n",")"],"metadata":{"id":"Sj1itmO9Y_0L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dividimos la mjuestra en train y test"],"metadata":{"id":"ymV81IiwZJuL"}},{"cell_type":"code","source":["y = pd.DataFrame(data.resultado)\n","x = pd.DataFrame(data_inputs)"],"metadata":{"id":"tlmCVsAGZIlX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size = 0.3,random_state = 12)"],"metadata":{"id":"j2YkUPr8ZXLv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Construcción del modelo"],"metadata":{"id":"0kzdDMhSZbZ1"}},{"cell_type":"code","source":["class DCNN(tf.keras.Model):\n","  \n","  def __init__(self,\n","             vocab_size,\n","             emb_dim = 128,\n","             nb_filters = 50, \n","             FFN_units = 512,\n","             nb_classes = 2,\n","             dropout_rate = 0.1,\n","             training = False,\n","             name = \"dcnn\"):\n","    \n","    super(DCNN, self).__init__(name=name)\n","\n","    self.embedding = layers.Embedding(vocab_size,\n","        emb_dim)\n","    \n","    self.bigram = layers.Conv1D(filters = nb_filters,\n","    kernel_size = 2,\n","    padding = \"valid\",\n","    activation = \"relu\")\n","    \n","    self.trigram = layers.Conv1D(filters = nb_filters,\n","                                kernel_size = 3,\n","                                padding = \"valid\",\n","                                activation = \"relu\")\n","     \n","    self.fourgram = layers.Conv1D(filters = nb_filters,\n","                                kernel_size = 4,\n","                                padding = \"valid\",\n","                                activation = \"relu\")\n","    \n","    self.pool = layers.GlobalMaxPool1D()\n","\n","\n","    self.dense_1 = layers.Dense(units = FFN_units, activation = \"relu\")\n","    self.dropout = layers.Dropout(rate = dropout_rate)\n","    if nb_classes == 2:\n","        self.last_dense = layers.Dense(units = 1, activation = \"sigmoid\")\n","    else:\n","      self.last_dense = layers.Dense(units = nb_classes,activation = \"softmax\") \n","\n","  def call(self,inputs, training):\n","    x = self.embedding(inputs)\n","    x_1 = self.bigram(x)\n","    x_1 = self.pool(x_1)       \n","    x_2 = self.trigram(x)\n","    x_2 = self.pool(x_2)         \n","    x_3 = self.fourgram(x)\n","    x_3 = self.pool(x_3)\n","\n","    merged = tf.concat([x_1,x_2,x_3], axis = -1)# con el -1 le digo el último eje de la combinacion // batch_size,3*nb_filters\n","    merged = self.dense_1(merged)\n","    merged = self.dropout(merged, training)\n","    output = self.last_dense(merged)\n","\n","    return output             \n"," #vocab_size,# tamaño de las palabras a trabajar\n","  #           emb_dim = 128,# a que espacio vectorial vamos a llevar nuestras palabras (cada una de ellas se irá a un espacio de 128 dimensiones)\n","   #          nb_filters = 50, # cuantas palabras filtra\n","    #         FNN_units 512,# numero de neuronas\n","     #        nb_classes = 2,# categorias de clasificacion\n","  #dropout_rate = 0.1, evitar el overfitting, el 10% de las neuronas no aprenderan transmitiran lo aprendido"],"metadata":{"id":"d7P7PMzUZe3Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Aplicación"],"metadata":{"id":"Je7vnq9OZxQN"}},{"cell_type":"markdown","source":["### Configuración de parámetros"],"metadata":{"id":"Zg26wxl0a1QP"}},{"cell_type":"code","source":["VOCAB_SIZE = tokenizer.vocab_size\n","\n","EMB_DIM = 200\n","NB_FILTERS = 100\n","FFN_UNITS = 256\n","NB_CLASSES = 2 #LEN(SET(TRAIN_LABELS))\n","\n","DROPOUT_RATE = 0.4 # razón de no aprendizaje de las neuronas\n","BATCH_SIZE = 32\n","NB_EPOCHS = 2"],"metadata":{"id":"l6tftBqKZjQZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Entrenamiento"],"metadata":{"id":"6BaIHSu_bHU7"}},{"cell_type":"code","source":["Dcnn = DCNN(vocab_size = VOCAB_SIZE,\n","            emb_dim = EMB_DIM,\n","            nb_filters = NB_FILTERS,\n","            FFN_units = FFN_UNITS,\n","            nb_classes = NB_CLASSES,\n","            dropout_rate = DROPOUT_RATE)"],"metadata":{"id":"IWLtimn7bHCs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if NB_CLASSES == 2:\n","  Dcnn.compile (loss = \"binary_crossentropy\",\n","                optimizer = \"adam\",\n","                metrics = [\"accuracy\"])\n","else:\n","  Dcnn.compile(loss= \"sparse_categorical_crossentropy\",\n","               optimizer = \"adam\",\n","               metrics = [\"sparse_categorical_accuracy\"])  "],"metadata":{"id":"v1W-P5UubNZ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/CNN Spam Ham/check_point'\n","\n","#ckpt = tf.train.Checkpoint(Dcnn = Dcnn)\n","\n","#ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep = 10)\n","\n","#if ckpt_manager.latest_checkpoint:\n","#  ckpt.restore(ckpt_manager.lastest_checkpoint)\n"," # print(\"Último checkpoint restaurado\")"],"metadata":{"id":"YjafL4cmbQGr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Dcnn.fit(X_train,\n","         Y_train,\n","         batch_size = BATCH_SIZE,\n","         epochs = NB_EPOCHS)\n","#ckpt_manager.save()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LnsCtOoebryd","executionInfo":{"status":"ok","timestamp":1661474404950,"user_tz":240,"elapsed":4914,"user":{"displayName":"FELIPE LERMANDA RODRIGUEZ","userId":"01039212382747188054"}},"outputId":"005f9158-5c1a-40aa-9142-06e4fbe4ab27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","29/29 [==============================] - 3s 57ms/step - loss: 0.6085 - accuracy: 0.7464\n","Epoch 2/2\n","29/29 [==============================] - 2s 56ms/step - loss: 0.1759 - accuracy: 0.9745\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3d91e7a0d0>"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## Evaluación"],"metadata":{"id":"vk5JQ3ohsNbN"}},{"cell_type":"code","source":["results = Dcnn.evaluate(X_test,Y_test,batch_size = BATCH_SIZE)\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ononvPlBxsLZ","executionInfo":{"status":"ok","timestamp":1661474410482,"user_tz":240,"elapsed":898,"user":{"displayName":"FELIPE LERMANDA RODRIGUEZ","userId":"01039212382747188054"}},"outputId":"e7cd4080-ef95-4c64-e26d-de30b5bb8c2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["13/13 [==============================] - 0s 13ms/step - loss: 0.1100 - accuracy: 0.9690\n","[0.1100362241268158, 0.9689922332763672]\n"]}]},{"cell_type":"code","source":["Dcnn(np.array([tokenizer.encode(\"https: you win game\")]),training = False).numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lm__biL0bv21","executionInfo":{"status":"ok","timestamp":1661475182934,"user_tz":240,"elapsed":413,"user":{"displayName":"FELIPE LERMANDA RODRIGUEZ","userId":"01039212382747188054"}},"outputId":"dd9cb9df-6677-4291-8a62-feea9fd7fa2c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.21101636]], dtype=float32)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["#from sklearn.metrics import classification_report\n","\n","#clf = grid_search.best_estimator_\n","#pred_lda = clf.predict(X_test)\n","\n","#print(classification_report(Y_test, pred_lda))"],"metadata":{"id":"APfT2-maxcBl"},"execution_count":null,"outputs":[]}]}